This is a classic dataset, but it is **perfect** for the "Story Arc" required by your syllabus because it has a specific challenge: **Class Imbalance**. Most wines are "average" (scores 5, 6, 7), and very few are excellent (8-9) or poor (3-4).

This gives us a great opportunity to show "Trial and Error":
1.  **Attempt 1:** Treat it as a Regression problem (predict the score 0-10) using Linear Regression. -> *Likely fails to capture the nuance.*
2.  **Attempt 2:** Treat it as a Multi-class classification (predict 3, 4, 5, 6...). -> *Likely struggles with the rare classes.*
3.  **Attempt 3 (The Solution):** Feature Engineering + Binning. We group the target into "Low Quality", "Average", and "High Quality" (or just Binary "Good vs Bad") and use Random Forest/SVM.

Let's start building the Notebook.

---

### **Step 1: Problem Definition & Data Loading**

Create a new Jupyter Notebook. Below is the content for the first few cells. I have written the **Markdown** (Text) and the **Code** separately.

#### **Cell 1 [Markdown]: Title and Introduction**
Copy and paste this into the first cell (change type to Markdown):

```markdown
# End-Term Project: Wine Quality Prediction

## 1. Problem Definition
**Objective:** The goal of this project is to predict the quality of white "Vinho Verde" wine based on physicochemical tests.

**Why is this important?**
Winemaking is a complex chemical process. Identifying the specific chemical properties (like acidity, sugar, and alcohol) that lead to a "high quality" sensory rating can help producers improve their manufacturing process and ensure consistency.

**The Dataset:**
We are using the `winequality-white.csv` dataset.
- **Input:** 11 physicochemical features (e.g., fixed acidity, pH, alcohol).
- **Target:** `quality` (a score between 0 and 10).
- **Type of Problem:** This can be framed as a Regression task (predicting the score) or a Classification task (categorizing quality tiers). We will explore both.
```

#### **Cell 2 [Code]: Imports and Configuration**
We will import the libraries covered in your course (NumPy, Pandas, Matplotlib, Seaborn).

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Configuration for clearer visualization
sns.set(style="whitegrid")
%matplotlib inline

# Helper function to load data (Modular code requirement)
def load_data(path):
    """
    Loads the CSV data with the correct separator.
    """
    try:
        # The dataset uses ';' as a separator, not the default ','
        df = pd.read_csv(path, sep=';')
        print(f"Data loaded successfully. Shape: {df.shape}")
        return df
    except FileNotFoundError:
        print("Error: File not found.")
        return None

# Load the dataset
df = load_data('winequality-white.csv')
```

#### **Cell 3 [Code]: Initial Data Inspection**
We need to verify the data types and check for immediate issues.

```python
# Display the first few rows to understand the structure
display(df.head())

# Check data types and look for missing values
print("\n--- Data Info ---")
df.info()

# Check for duplicates (common in this specific dataset)
duplicates = df.duplicated().sum()
print(f"\nNumber of duplicate rows: {duplicates}")
```

---

### **Analysis of Step 1 (To be included in your thought process)**

Once you run this code, you will notice something specific about this dataset that we must address in the next step (Data Processing):
1.  **Duplicates:** This dataset often contains duplicate rows (because two different wines can have the exact same chemical makeup). Your syllabus (Page 2, Section 4) explicitly says: *"detects data quality issues, such as... duplicates."* We **must** decide whether to remove them. (Plan: We will remove them to prevent data leakage between train/test sets).
2.  **Data Types:** All features are numeric (float/int). No text encoding is needed yet.

**Are you ready for Step 2: Deep Exploratory Data Analysis (EDA)?**
If yes, I will provide the code to visualize the distributions and correlations, which will help us "tell the story" of the data.